"""MFT/USN/Rustå¼•æ“ç›¸å…³ï¼šä»åŸç‰ˆæå–ï¼Œé€»è¾‘ä¸æ”¹ã€‚"""
from __future__ import annotations
from ..utils.constants import *


# ==================== MFT/USN æ¨¡å— ====================


if IS_WINDOWS:
    import ctypes.wintypes as wintypes

    GENERIC_READ = 0x80000000
    GENERIC_WRITE = 0x40000000
    FILE_SHARE_READ = 0x00000001
    FILE_SHARE_WRITE = 0x00000002
    OPEN_EXISTING = 3
    FILE_FLAG_BACKUP_SEMANTICS = 0x02000000
    FSCTL_ENUM_USN_DATA = 0x000900B3
    FSCTL_QUERY_USN_JOURNAL = 0x000900F4
    FILE_ATTRIBUTE_DIRECTORY = 0x10

    class USN_JOURNAL_DATA_V0(ctypes.Structure):
        _fields_ = [
            ("UsnJournalID", ctypes.c_uint64),
            ("FirstUsn", ctypes.c_int64),
            ("NextUsn", ctypes.c_int64),
            ("LowestValidUsn", ctypes.c_int64),
            ("MaxUsn", ctypes.c_int64),
            ("MaximumSize", ctypes.c_uint64),
            ("AllocationDelta", ctypes.c_uint64),
        ]

    class USN_RECORD_V2(ctypes.Structure):
        _fields_ = [
            ("RecordLength", ctypes.c_uint32),
            ("MajorVersion", ctypes.c_uint16),
            ("MinorVersion", ctypes.c_uint16),
            ("FileReferenceNumber", ctypes.c_uint64),
            ("ParentFileReferenceNumber", ctypes.c_uint64),
            ("Usn", ctypes.c_int64),
            ("TimeStamp", ctypes.c_int64),
            ("Reason", ctypes.c_uint32),
            ("SourceInfo", ctypes.c_uint32),
            ("SecurityId", ctypes.c_uint32),
            ("FileAttributes", ctypes.c_uint32),
            ("FileNameLength", ctypes.c_uint16),
            ("FileNameOffset", ctypes.c_uint16),
        ]

    kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)

    CreateFileW = kernel32.CreateFileW
    CreateFileW.argtypes = [
        wintypes.LPCWSTR,
        wintypes.DWORD,
        wintypes.DWORD,
        wintypes.LPVOID,
        wintypes.DWORD,
        wintypes.DWORD,
        wintypes.HANDLE,
    ]
    CreateFileW.restype = wintypes.HANDLE

    DeviceIoControl = kernel32.DeviceIoControl
    DeviceIoControl.argtypes = [
        wintypes.HANDLE,
        wintypes.DWORD,
        wintypes.LPVOID,
        wintypes.DWORD,
        wintypes.LPVOID,
        wintypes.DWORD,
        ctypes.POINTER(wintypes.DWORD),
        wintypes.LPVOID,
    ]
    DeviceIoControl.restype = wintypes.BOOL

    CloseHandle = kernel32.CloseHandle
    INVALID_HANDLE_VALUE = ctypes.c_void_p(-1).value

    def enum_volume_files_mft(drive_letter, skip_dirs, skip_exts, allowed_paths=None):
        """MFTæšä¸¾æ–‡ä»¶"""
        global MFT_AVAILABLE

        if HAS_RUST_ENGINE:
            logger.info(f"ğŸš€ ä½¿ç”¨ Rust æ ¸å¿ƒå¼•æ“æ‰«æé©±åŠ¨å™¨ {drive_letter}...")
            result = None
            try:
                result = RUST_ENGINE.scan_drive_packed(ord(drive_letter.upper()[0]))

                if not result.data or result.count == 0:
                    raise Exception("ç©ºæ•°æ®")

                raw_data = ctypes.string_at(result.data, result.data_len)
                py_list = []
                off = 0
                n = len(raw_data)

                allowed_paths_lower = None
                if allowed_paths:
                    allowed_paths_lower = [p.lower().rstrip("\\") for p in allowed_paths]

                skipped_count = 0

                while off < n:
                    # æ–°æ ¼å¼ï¼ˆæ›´å¿«ï¼‰ï¼šä¸å†ä¼  name_lower
                    # [is_dir:1][name_len:2][path_len:2][parent_len:2][ext_len:1][size:8][mtime:8][data...]
                    if off + 24 > n:
                        break

                    is_dir = raw_data[off]
                    name_len = int.from_bytes(raw_data[off + 1:off + 3], "little")
                    path_len = int.from_bytes(raw_data[off + 3:off + 5], "little")
                    parent_len = int.from_bytes(raw_data[off + 5:off + 7], "little")
                    ext_len = raw_data[off + 7]
                    size = int.from_bytes(raw_data[off + 8:off + 16], "little")
                    mtime = struct.unpack("<d", raw_data[off + 16:off + 24])[0]
                    off += 24

                    total_len = name_len + path_len + parent_len + ext_len
                    if off + total_len > n:
                        break

                    name = raw_data[off:off + name_len].decode("utf-8", "replace")
                    off += name_len

                    path = raw_data[off:off + path_len].decode("utf-8", "replace")
                    off += path_len

                    parent = raw_data[off:off + parent_len].decode("utf-8", "replace")
                    off += parent_len

                    ext = raw_data[off:off + ext_len].decode("utf-8", "replace") if ext_len else ""
                    off += ext_len

                    name_lower = name.lower()
                    path_lower = path.lower()

                    # è¿‡æ»¤é€»è¾‘
                    if allowed_paths_lower:
                        in_allowed = False
                        for ap in allowed_paths_lower:
                            if path_lower.startswith(ap + "\\") or path_lower == ap:
                                in_allowed = True
                                break
                        if not in_allowed:
                            skipped_count += 1
                            continue
                    else:
                        if should_skip_path(path_lower, None):
                            skipped_count += 1
                            continue
                        if is_dir:
                            if should_skip_dir(name_lower, path_lower, None):
                                skipped_count += 1
                                continue
                        else:
                            if ext in skip_exts:
                                skipped_count += 1
                                continue

                    # â˜… ç°åœ¨ size å’Œ mtime å·²ç»ä» Rust è·å–ï¼Œæ— éœ€åç»­å¤„ç†
                    py_list.append((name, name_lower, path, parent, ext, size, mtime, is_dir))

                logger.info(f"âœ… Rustè¿”å›={result.count}, è·³è¿‡={skipped_count}, ä¿ç•™={len(py_list)}")

                MFT_AVAILABLE = True
                return py_list

            except Exception as e:
                logger.error(f"Rust å¼•æ“é”™è¯¯: {e}ï¼Œå›é€€åˆ° Python")
                import traceback
                traceback.print_exc()
            finally:
                if result and result.data:
                    try:
                        RUST_ENGINE.free_scan_result(result)
                    except:
                        pass

        # Python MFT å®ç°
        return _enum_volume_files_mft_python(drive_letter, skip_dirs, skip_exts, allowed_paths)


    # ==================== æ–°çš„ä¼˜åŒ–ç‰ˆå‡½æ•°ï¼ˆæ›¿æ¢è¿™é‡Œï¼‰====================
    def _batch_stat_files(
        py_list,
        only_missing=True,
        write_back_db=False,
        db_conn=None,
        db_lock=None,
    ):
        """
        æ‰¹é‡è·å–æ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´ï¼ˆå¢å¼ºç‰ˆï¼‰
        - only_missing=True: åªè¡¥é½ size/mtime ä¸º 0 çš„é¡¹ï¼ˆæ‡’åŠ è½½æ¨èï¼‰
        - write_back_db=True: å¯é€‰å†™å›æ•°æ®åº“ï¼ˆéœ€è¦ä¼  db_conn + db_lockï¼‰
        py_list item æ ¼å¼è¦æ±‚: [name, name_lower, path, parent, ext, size, mtime, is_dir]
        """
        if not py_list:
            return

        files_to_stat = []
        for item in py_list:
            try:
                # item[7] == 0 è¡¨ç¤ºæ–‡ä»¶ï¼Œ1 è¡¨ç¤ºç›®å½•
                if item[7] != 0:
                    continue

                # æ‡’åŠ è½½ï¼šåªå¤„ç†ç¼ºå¤±çš„
                if only_missing and (item[5] != 0 or item[6] != 0):
                    continue

                files_to_stat.append(item)
            except Exception:
                continue

        if not files_to_stat:
            return

        total_files = len(files_to_stat)
        start_time = time.time()

        # Windows API
        GetFileAttributesExW = kernel32.GetFileAttributesExW
        GetFileAttributesExW.restype = wintypes.BOOL
        GetFileAttributesExW.argtypes = [wintypes.LPCWSTR, ctypes.c_int, ctypes.c_void_p]

        class WIN32_FILE_ATTRIBUTE_DATA(ctypes.Structure):
            _fields_ = [
                ("dwFileAttributes", wintypes.DWORD),
                ("ftCreationTime", wintypes.FILETIME),
                ("ftLastAccessTime", wintypes.FILETIME),
                ("ftLastWriteTime", wintypes.FILETIME),
                ("nFileSizeHigh", wintypes.DWORD),
                ("nFileSizeLow", wintypes.DWORD),
            ]

        EPOCH_DIFF = 116444736000000000

        def stat_worker(batch):
            data = WIN32_FILE_ATTRIBUTE_DATA()
            updates = []  # (size, mtime, full_path)

            for item in batch:
                try:
                    path = item[2]
                    if GetFileAttributesExW(path, 0, ctypes.byref(data)):
                        size = (data.nFileSizeHigh << 32) + data.nFileSizeLow
                        mtime_ft = (data.ftLastWriteTime.dwHighDateTime << 32) + data.ftLastWriteTime.dwLowDateTime
                        if mtime_ft > EPOCH_DIFF:
                            mtime = (mtime_ft - EPOCH_DIFF) / 10000000.0
                        else:
                            mtime = 0.0

                        item[5] = int(size)
                        item[6] = float(mtime)

                        if write_back_db:
                            updates.append((int(size), float(mtime), path))
                except Exception:
                    pass

            return updates

        # çº¿ç¨‹æ•°ï¼šä¸è¦å¤ªå¤¸å¼ ï¼Œæ…¢ç›˜ä¼šè¢«æ‰“çˆ†
        if total_files < 200:
            num_workers = 4
        elif total_files < 2000:
            num_workers = 8
        else:
            num_workers = 16

        batch_size = max(50, (total_files + num_workers - 1) // num_workers)
        batches = [
            files_to_stat[i:i + batch_size]
            for i in range(0, total_files, batch_size)
        ]

        all_updates = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as ex:
            for ups in ex.map(stat_worker, batches):
                if ups:
                    all_updates.extend(ups)

        # å¯é€‰å†™å› DB
        if write_back_db and all_updates and db_conn is not None:
            try:
                if db_lock is not None:
                    with db_lock:
                        cur = db_conn.cursor()
                        cur.executemany(
                            "UPDATE files SET size=?, mtime=? WHERE full_path=?",
                            all_updates,
                        )
                        if not HAS_APSW:
                            db_conn.commit()
                else:
                    cur = db_conn.cursor()
                    cur.executemany(
                        "UPDATE files SET size=?, mtime=? WHERE full_path=?",
                        all_updates,
                    )
                    if not HAS_APSW:
                        db_conn.commit()
            except Exception as e:
                logger.debug(f"[statå›å†™] å†™å›æ•°æ®åº“å¤±è´¥: {e}")

        elapsed = time.time() - start_time
        speed = total_files / elapsed if elapsed > 0 else 0
        logger.info(f"è¡¥é½å®Œæˆ: {total_files} ä¸ªæ–‡ä»¶, è€—æ—¶ {elapsed:.2f}s, é€Ÿåº¦ {speed:.0f}/s")


    def _enum_volume_files_mft_python(drive_letter, skip_dirs, skip_exts, allowed_paths=None):
        """Python MFT å®ç°"""
        global MFT_AVAILABLE
        
        logger.info(f"ä½¿ç”¨ Python MFT å®ç°æ‰«æé©±åŠ¨å™¨ {drive_letter}...")
        drive = drive_letter.rstrip(":").upper()
        root_path = f"{drive}:\\"

        volume_path = f"\\\\.\\{drive}:"
        h = CreateFileW(
            volume_path,
            GENERIC_READ | GENERIC_WRITE,
            FILE_SHARE_READ | FILE_SHARE_WRITE,
            None,
            OPEN_EXISTING,
            FILE_FLAG_BACKUP_SEMANTICS,
            None,
        )
        if h == INVALID_HANDLE_VALUE:
            error_code = ctypes.get_last_error()
            logger.error(f"æ‰“å¼€å·å¤±è´¥ {drive}: é”™è¯¯ä»£ç  {error_code}")
            raise OSError(f"æ‰“å¼€å·å¤±è´¥: {error_code}")

        try:
            jd = USN_JOURNAL_DATA_V0()
            br = wintypes.DWORD()
            if not DeviceIoControl(
                h,
                FSCTL_QUERY_USN_JOURNAL,
                None,
                0,
                ctypes.byref(jd),
                ctypes.sizeof(jd),
                ctypes.byref(br),
                None,
            ):
                error_code = ctypes.get_last_error()
                logger.error(f"æŸ¥è¯¢USNå¤±è´¥ {drive}: é”™è¯¯ä»£ç  {error_code}")
                raise OSError(f"æŸ¥è¯¢USNå¤±è´¥: {error_code}")

            MFT_AVAILABLE = True
            records = {}
            BUFFER_SIZE = 1024 * 1024
            buf = (ctypes.c_ubyte * BUFFER_SIZE)()

            class MFT_ENUM_DATA(ctypes.Structure):
                _pack_ = 8
                _fields_ = [
                    ("StartFileReferenceNumber", ctypes.c_uint64),
                    ("LowUsn", ctypes.c_int64),
                    ("HighUsn", ctypes.c_int64),
                ]

            med = MFT_ENUM_DATA()
            med.StartFileReferenceNumber = 0
            med.LowUsn = 0
            med.HighUsn = jd.NextUsn

            allowed_paths_lower = (
                [p.lower().rstrip("\\") for p in allowed_paths]
                if allowed_paths
                else None
            )

            total = 0
            start_time = time.time()

            while True:
                ctypes.set_last_error(0)
                ok = DeviceIoControl(
                    h,
                    FSCTL_ENUM_USN_DATA,
                    ctypes.byref(med),
                    ctypes.sizeof(med),
                    ctypes.byref(buf),
                    BUFFER_SIZE,
                    ctypes.byref(br),
                    None,
                )
                err = ctypes.get_last_error()
                returned = br.value

                if not ok:
                    if err == 38:
                        break
                    if err != 0:
                        logger.error(f"MFTæšä¸¾å¤±è´¥ {drive}: é”™è¯¯ä»£ç  {err}")
                        raise OSError(f"æšä¸¾å¤±è´¥: {err}")
                    if returned <= 8:
                        break
                if returned <= 8:
                    break

                next_frn = ctypes.cast(
                    ctypes.byref(buf), ctypes.POINTER(ctypes.c_uint64)
                )[0]
                offset = 8
                batch_count = 0

                while offset < returned:
                    if offset + 4 > returned:
                        break
                    rec_len = ctypes.cast(
                        ctypes.byref(buf, offset), ctypes.POINTER(ctypes.c_uint32)
                    )[0]
                    if rec_len == 0 or offset + rec_len > returned:
                        break

                    if rec_len >= ctypes.sizeof(USN_RECORD_V2):
                        rec = ctypes.cast(
                            ctypes.byref(buf, offset), ctypes.POINTER(USN_RECORD_V2)
                        ).contents
                        name_off, name_len = rec.FileNameOffset, rec.FileNameLength
                        if name_len > 0 and offset + name_off + name_len <= returned:
                            filename = bytes(
                                buf[offset + name_off : offset + name_off + name_len]
                            ).decode("utf-16le", errors="replace")
                            if filename and filename[0] not in ("$", "."):
                                file_ref = rec.FileReferenceNumber & 0x0000FFFFFFFFFFFF
                                parent_ref = (
                                    rec.ParentFileReferenceNumber & 0x0000FFFFFFFFFFFF
                                )
                                is_dir = bool(
                                    rec.FileAttributes & FILE_ATTRIBUTE_DIRECTORY
                                )
                                records[file_ref] = (filename, parent_ref, is_dir)
                                batch_count += 1
                    offset += rec_len

                total += batch_count
                if total and total % 100000 < batch_count:
                    logger.info(
                        f"[MFT] {drive}: å·²æšä¸¾ {total:,} æ¡, ç”¨æ—¶ {time.time()-start_time:.1f}s"
                    )

                med.StartFileReferenceNumber = next_frn
                if batch_count == 0:
                    break

            logger.info(f"[MFT] {drive}: æšä¸¾å®Œæˆ {len(records):,} æ¡")

            # æ„å»ºè·¯å¾„
            result = _build_paths_from_records(
                records, root_path, drive, skip_exts, allowed_paths_lower
            )

            return result
        finally:
            CloseHandle(h)

    def _build_paths_from_records(
        records, root_path, drive, skip_exts, allowed_paths_lower
    ):
        """ä»MFTè®°å½•æ„å»ºå®Œæ•´è·¯å¾„"""
        logger.info(f"[MFT] {drive}: å¼€å§‹æ„å»ºè·¯å¾„...")

        dirs = {}
        files = {}
        parent_to_children = {}

        for ref, (name, parent_ref, is_dir) in records.items():
            if is_dir:
                dirs[ref] = (name, parent_ref)
                if parent_ref not in parent_to_children:
                    parent_to_children[parent_ref] = []
                parent_to_children[parent_ref].append(ref)
            else:
                files[ref] = (name, parent_ref)

        path_cache = {5: root_path}
        q = deque([5])

        while q:
            parent_ref = q.popleft()
            parent_path = path_cache.get(parent_ref)
            if not parent_path:
                continue

            parent_path_lower = parent_path.lower()
            if should_skip_path(
                parent_path_lower, allowed_paths_lower
            ) or should_skip_dir(
                os.path.basename(parent_path_lower),
                parent_path_lower,
                allowed_paths_lower,
            ):
                continue

            if parent_ref in parent_to_children:
                for child_ref in parent_to_children[parent_ref]:
                    child_name, _ = dirs[child_ref]
                    child_path = os.path.join(parent_path, child_name)
                    path_cache[child_ref] = child_path
                    q.append(child_ref)

        logger.info(
            f"[MFT] {drive}: ç›®å½•è·¯å¾„æ„å»ºå®Œæˆï¼Œç¼“å­˜äº† {len(path_cache):,} ä¸ªæœ‰æ•ˆç›®å½•ã€‚"
        )

        result = []

        # æ·»åŠ ç›®å½•
        for ref, (name, parent_ref) in dirs.items():
            full_path = path_cache.get(ref)
            if not full_path or full_path == root_path:
                continue
            parent_dir = path_cache.get(parent_ref, root_path)
            result.append([name, name.lower(), full_path, parent_dir, "", 0, 0, 1])

        # æ·»åŠ æ–‡ä»¶
        for ref, (name, parent_ref) in files.items():
            parent_path = path_cache.get(parent_ref)
            if not parent_path:
                continue

            full_path = os.path.join(parent_path, name)

            if should_skip_path(full_path.lower(), allowed_paths_lower):
                continue

            ext = os.path.splitext(name)[1].lower()
            if ext in skip_exts:
                continue

            if allowed_paths_lower and not is_in_allowed_paths(
                full_path.lower(), allowed_paths_lower
            ):
                continue

            result.append([name, name.lower(), full_path, parent_path, ext, 0, 0, 0])

        logger.info(f"[MFT] {drive}: è·¯å¾„æ‹¼æ¥ä¸è¿‡æ»¤å®Œæˆï¼Œæ€»è®¡ {len(result):,} æ¡ã€‚")

        # æ‰¹é‡è·å–æ–‡ä»¶ä¿¡æ¯
        _batch_stat_files(result)

        logger.info(f"[MFT] {drive}: è¿‡æ»¤å {len(result):,} æ¡")
        return [tuple(item) for item in result]

else:

    def enum_volume_files_mft(drive_letter, skip_dirs, skip_exts, allowed_paths=None):
        raise OSError("MFTä»…Windowså¯ç”¨")

        # ==================== ç´¢å¼•ç®¡ç†å™¨ ====================

